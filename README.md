Tema 4. ILUMINACI√ìN parte 1 de 3 , abajo parte 2
4.1. Importancia de la iluminaci√≥n en visi√≥n por computadora.

4.2. Problemas relacionados con la iluminaci√≥n.

4.3. Preprocesamiento de im√°genes.

4.4. Aumento de datos espec√≠fico para la iluminaci√≥n.

READMEN DE REPORTE
# üêï Proyecci√≥n de Im√°genes con PCA y UMAP (Stanford Dogs Dataset)

## üìå Tarea de la Semana 9: An√°lisis Visual de Dimensionalidad

Este proyecto aplica t√©cnicas de **reducci√≥n de dimensionalidad** (PCA y UMAP) sobre un subconjunto del **Stanford Dogs Dataset** para visualizar c√≥mo se agrupan las diferentes razas en un espacio de baja dimensi√≥n (2D y 3D), despu√©s de un preprocesamiento de im√°genes que incluye aumento de iluminaci√≥n.

### üéØ Objetivo

Visualizar la estructura latente de las representaciones de im√°genes mediante t√©cnicas lineales y no lineales, demostrando la robustez de las caracter√≠sticas de la imagen frente a variaciones de iluminaci√≥n.

### üõ†Ô∏è Pipeline de Procesamiento

1.  **Carga del Dataset:** Extracci√≥n del conjunto de im√°genes del Stanford Dogs Dataset.
2.  **Aumento de Iluminaci√≥n:** Aplicaci√≥n de variaciones aleatorias de **Brillo ($\beta$)** y **Contraste ($\alpha$)** a cada imagen para simular diversas condiciones de luz y mejorar la robustez.
    $$\text{Imagen Ajustada} = \alpha \cdot \text{Imagen Original} + \beta$$
3.  **Conversi√≥n y Aplanamiento:**
    * Redimensi√≥n a $128 \times 128 \times 3$ y normalizaci√≥n a $[0, 1]$.
    * Aplanamiento del tensor 4D a una matriz de vectores de caracter√≠sticas de alta dimensi√≥n.
4.  **Reducci√≥n de Dimensionalidad:** Proyecci√≥n de los vectores a 3 dimensiones utilizando:
    * **PCA (An√°lisis de Componentes Principales):** M√©todo lineal que maximiza la varianza.
    * **UMAP (Uniform Manifold Approximation and Projection):** M√©todo no lineal que preserva la estructura topol√≥gica local.

### üìä Resultados y An√°lisis

Los resultados se visualizan mediante gr√°ficos de dispersi√≥n 2D y 3D, donde cada punto representa una imagen y el color indica la raza.

* **PCA:** Muestra una **superposici√≥n significativa** de las razas, lo que sugiere que las caracter√≠sticas distintivas de las razas no son linealmente separables en los primeros componentes principales.
* **UMAP:** Logra una **mejor segregaci√≥n y cl√∫steres m√°s compactos**, demostrando su capacidad para capturar las relaciones no lineales y la estructura intr√≠nseca del *manifold* de las im√°genes.

### üì¶ Tecnolog√≠as Utilizadas

* `Python 3.x`
* `scikit-learn` (para PCA)
* `umap-learn` (para UMAP)
* `OpenCV (cv2)` (para Preprocesamiento de im√°genes)
* `matplotlib`, `seaborn`, `plotly` (para Visualizaci√≥n)
* `numpy`

### üöÄ Uso

1.  Clonar el repositorio.
2.  Asegurar el archivo `perros.zip` del Stanford Dogs Dataset en la ruta de trabajo.
3.  Ejecutar el *notebook* de Colab o Jupyter.


PARTE 2 DE 3
# üí° DEEP LEARNIN & ML_ILUMINACION_VISION_COMPUTADORA

## üìÑ Semana 10: Fundamentos de CNN, Convoluci√≥n y Pooling

Este repositorio contiene el c√≥digo desarrollado y ejecutado para la demostraci√≥n de los componentes fundamentales de las Redes Neuronales Convolucionales (CNN) y su aplicaci√≥n inicial en el contexto de la visi√≥n por computadora.

El enfoque principal de este notebook es la **validaci√≥n conceptual** de c√≥mo los modelos procesan datos espaciales (im√°genes), desde la unidad m√°s b√°sica (el perceptr√≥n) hasta las operaciones clave de una capa convolucional.

### üõ†Ô∏è Contenido del Notebook

El archivo `Semana_10_Con tarea.ipynb` incluye las siguientes demostraciones pr√°cticas:

1.  **Perceptr√≥n y Separabilidad Lineal:** Implementaci√≥n y entrenamiento de un perceptr√≥n simple para resolver la compuerta l√≥gica AND, incluyendo la visualizaci√≥n de la frontera de decisi√≥n.
2.  **Convoluci√≥n 2D Fundamental:** Demostraci√≥n manual de la operaci√≥n de convoluci√≥n utilizando una imagen artificial y un kernel detector de bordes, ilustrando el proceso de generaci√≥n de mapas de caracter√≠sticas.
3.  **Pipeline de Procesamiento CNN en Im√°genes Reales:** Aplicaci√≥n de filtros de convoluci√≥n y la operaci√≥n de Max Pooling sobre im√°genes del Stanford Dogs Dataset (o im√°genes de ejemplo) para simular la extracci√≥n de caracter√≠sticas y la reducci√≥n de dimensionalidad espacial:
    * Detecci√≥n de Bordes (Filtro Sobel/Laplaciano).
    * Suavizado (*Blur*).
    * Max Pooling Iterativo (generaci√≥n de una jerarqu√≠a de caracter√≠sticas abstractas).

### üéØ Objetivos de Aprendizaje

* Comprender el rol de la neurona y las funciones de activaci√≥n (ReLU, Sigmoide).
* Visualizar la **invariancia traslacional** lograda mediante el compartimiento de pesos en la convoluci√≥n.
* Analizar c√≥mo la operaci√≥n de **Max Pooling** reduce la resoluci√≥n mientras conserva las caracter√≠sticas dominantes, contribuyendo a la robustez del modelo.

### üì¶ Dependencias

* numpy
* matplotlib
* opencv-python (cv2)


PARTE 3 DE 3

üß† Clasificaci√≥n Avanzada de Im√°genes con Deep Learning (Stanford Dogs Dataset)Este repositorio contiene la implementaci√≥n y el an√°lisis comparativo de modelos de Deep Learning (DL) para la tarea de clasificaci√≥n de grano fino (Fine-Grained Classification) utilizando el desafiante Stanford Dogs Dataset (120 razas de perros).El objetivo principal es evaluar y comparar el rendimiento y la eficiencia de diferentes arquitecturas neuronales (MLP, LSTM, CNN) y la t√©cnica de Transferencia de Conocimiento (Transfer Learning) en un contexto de alta complejidad visual.üõ†Ô∏è Estructura del Pipeline de EntrenamientoEl c√≥digo sigue un protocolo de experimentaci√≥n riguroso, optimizado para la reproducibilidad y el rendimiento en un entorno como Google Colab (utilizando TensorFlow y Keras).1. Preparaci√≥n y Optimizaci√≥n del DatasetReproducibilidad: Uso de una semilla fija (SEED = 42) para garantizar la consistencia en la inicializaci√≥n de pesos y la divisi√≥n de los datos.Pipeline de Datos (tf.data): Implementaci√≥n de t√©cnicas avanzadas como caching, prefetching y shuffling para maximizar el rendimiento de la GPU/CPU durante el entrenamiento.Normalizaci√≥n: Escalado de las im√°genes a un rango de [0, 1].Adaptaci√≥n de Tensors: Funciones espec√≠ficas para reestructurar las im√°genes para cada arquitectura:MLP: Imagen aplanada a vector 1D.LSTM: Imagen transformada a una secuencia de filas (Tiempo x Caracter√≠sticas).CNN/TL: Mantenimiento de la forma espacial (H x W x C).2. Control del Aprendizaje (Callbacks)Se utilizan callbacks para gestionar el proceso de entrenamiento de forma autom√°tica y robusta:EarlyStopping: Detiene el entrenamiento al detectar sobreajuste (monitoreando la p√©rdida de validaci√≥n).ReduceLROnPlateau: Ajusta din√°micamente la tasa de aprendizaje para mejorar la convergencia en etapas finales.ModelCheckpoint: Guarda la versi√≥n del modelo que alcanza el mejor desempe√±o en el conjunto de validaci√≥n.3. Arquitecturas y Comparativa de RendimientoEl coraz√≥n del proyecto es la comparaci√≥n de cuatro enfoques distintos:ModeloTipo de EstructuraFunci√≥n en el An√°lisisMLP (L√≠nea Base)Vectorial (Densas)Eval√∫a el desempe√±o sin estructura espacial.LSTM BidireccionalSecuencial/TemporalEval√∫a la imagen como una secuencia de filas.CNN BaselineEspacial (Convolucional)Est√°ndar para CV; extrae jerarqu√≠as de caracter√≠sticas locales.Transfer Learning (MobileNetV2)Preentrenado + Fine-TuningReutiliza conocimiento de ImageNet para lograr la m√°xima precisi√≥n y r√°pida convergencia.4. Evaluaci√≥n ProfundaEl c√≥digo incluye un conjunto de funciones de evaluaci√≥n avanzadas para una visi√≥n integral del rendimiento:plot_history: Visualizaci√≥n de curvas de P√©rdida (Loss) y Precisi√≥n (Accuracy) en entrenamiento y validaci√≥n.eval_and_report: Generaci√≥n del Reporte de Clasificaci√≥n (Precisi√≥n, Recall, F1-Score por clase) y la Matriz de Confusi√≥n (heatmap).show_sample_predictions: Muestras visuales de las predicciones (aciertos ‚úÖ / errores ‚ùå) para un an√°lisis cualitativo.üöÄ Tecnolog√≠as ClavePython 3.xTensorFlow / Keras (Core DL framework)tf.data (Optimizaci√≥n de pipelines de datos)numpymatplotlib y seaborn (Visualizaci√≥n de resultados)scikit-learn (Generaci√≥n de Reportes y Matriz de Confusi√≥n)
